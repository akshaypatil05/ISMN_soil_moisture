{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d451516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ismn.interface import ISMN_Interface\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c4bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the existing ismn metadata in data\\africa\\python_metadata\\Data_separate_files_header_20160614_20250614_11438_iyLN_20250614.csv to set up ISMN_Interface. \n",
      "If there are issues with the data reader, you can remove the metadata csv file to repeat metadata collection.\n",
      "Data will be extracted for these station:  ['AMMA-CATCH', 'SD_DEM', 'TAHMO']\n"
     ]
    }
   ],
   "source": [
    "path = r'data\\africa\\Data_separate_files_header_20160614_20250614_11438_iyLN_20250614.zip'\n",
    "ismn_data = ISMN_Interface(path, parallel=True)\n",
    "network_list=[]\n",
    "for i in ismn_data.networks:\n",
    "    network_list.append(i)\n",
    "print('Data will be extracted for these station: ', network_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab022ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static(sm):\n",
    "\n",
    "    static_data = []\n",
    "\n",
    "    for sensor_idx in range(sm.dims['sensor']):\n",
    "        sensor_data = {\n",
    "            'sensor_id': sensor_idx,\n",
    "            'network': sm.network.values[sensor_idx] if 'network' in sm.variables else 'AMMA-CATCH',\n",
    "            'station': sm.station.values[sensor_idx] if 'station' in sm.variables else f'Station_{sensor_idx}',\n",
    "            'sensor_name': str(sm.instrument.values[sensor_idx]) if 'instrument' in sm.variables else f'Sensor_{sensor_idx}',\n",
    "            'latitude': float(sm.latitude.values[sensor_idx]),\n",
    "            'longitude': float(sm.longitude.values[sensor_idx]),\n",
    "            'elevation': float(sm.elevation.values[sensor_idx]) if 'elevation' in sm.variables else np.nan,\n",
    "            'depth_from': float(sm.depth_from.values[sensor_idx]) if 'depth_from' in sm.variables else np.nan,\n",
    "            'depth_to': float(sm.depth_to.values[sensor_idx]) if 'depth_to' in sm.variables else np.nan,\n",
    "            'clay_fraction': float(sm.clay_fraction.values[sensor_idx]) if 'clay_fraction' in sm.variables else np.nan,\n",
    "            'sand_fraction': float(sm.sand_fraction.values[sensor_idx]) if 'sand_fraction' in sm.variables else np.nan,\n",
    "            'silt_fraction': float(sm.silt_fraction.values[sensor_idx]) if 'silt_fraction' in sm.variables else np.nan,\n",
    "            'organic_carbon': float(sm.organic_carbon.values[sensor_idx]) if 'organic_carbon' in sm.variables else np.nan,\n",
    "        }\n",
    "        static_data.append(sensor_data)\n",
    "\n",
    "    static_df = pd.DataFrame(static_data)\n",
    "\n",
    "    return static_df\n",
    "\n",
    "\n",
    "def get_sm_time_series(sm, statistic='mean'):\n",
    "    \"\"\"\n",
    "    Extracts time series of soil moisture data with a specified statistical operation.\n",
    "    \n",
    "    Parameters:\n",
    "    - sm: xarray dataset of soil moisture\n",
    "    - statistic: str, one of ['mean', 'median', 'min', 'max', 'sum', 'std']\n",
    "    \n",
    "    Returns:\n",
    "    - ts_df: pandas DataFrame with time series data\n",
    "    \"\"\"\n",
    "    # Convert time to datetime\n",
    "    sm_with_time = sm.assign_coords(date_time=pd.to_datetime(sm.date_time.values))\n",
    "    \n",
    "    # Select the aggregation method\n",
    "    if statistic == 'mean':\n",
    "        daily_sm = sm_with_time.soil_moisture.resample(date_time='D').mean()\n",
    "    elif statistic == 'median':\n",
    "        daily_sm = sm_with_time.soil_moisture.resample(date_time='D').median()\n",
    "    elif statistic == 'min':\n",
    "        daily_sm = sm_with_time.soil_moisture.resample(date_time='D').min()\n",
    "    elif statistic == 'max':\n",
    "        daily_sm = sm_with_time.soil_moisture.resample(date_time='D').max()\n",
    "    elif statistic == 'sum':\n",
    "        daily_sm = sm_with_time.soil_moisture.resample(date_time='D').sum()\n",
    "    elif statistic == 'std':\n",
    "        daily_sm = sm_with_time.soil_moisture.resample(date_time='D').std()\n",
    "    else:\n",
    "        raise ValueError(f\"Statistic '{statistic}' is not supported. Use 'mean', 'median', 'min', 'max', 'sum', or 'std'.\")\n",
    "    \n",
    "    # Prepare time series\n",
    "    dates = pd.to_datetime(daily_sm.date_time.values)\n",
    "    date_strings = [d.strftime('%Y-%m-%d') for d in dates]\n",
    "    sm_values = daily_sm.values  \n",
    "    \n",
    "    # Cleaning\n",
    "    valid_mask = (\n",
    "        (~np.isnan(sm_values)) & \n",
    "        (sm_values >= 0) & \n",
    "        (sm_values <= 1) & \n",
    "        (sm_values != -9999) & \n",
    "        (sm_values != -999)\n",
    "    )\n",
    "    sm_values_clean = np.where(valid_mask, sm_values, np.nan)\n",
    "\n",
    "    # Build DataFrame\n",
    "    ts_df = pd.DataFrame(sm_values_clean, columns=date_strings)\n",
    "    \n",
    "    return ts_df\n",
    "\n",
    "\n",
    "\n",
    "def export_gdf(gdf, output_path, file_format='geojson'):\n",
    "    \"\"\"\n",
    "    Export a GeoDataFrame to the specified format.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf: GeoDataFrame to export\n",
    "    - output_path: Path without file extension\n",
    "    - file_format: 'geojson', 'shp', 'parquet', 'gpkg'\n",
    "    \"\"\"\n",
    "    file_format = file_format.lower()\n",
    "\n",
    "    supported_formats = ['geojson', 'shp', 'parquet', 'gpkg','csv']\n",
    "\n",
    "    if file_format not in supported_formats:\n",
    "        raise ValueError(f\"Unsupported format: {file_format}. Supported formats are: {supported_formats}\")\n",
    "\n",
    "    # Set file extension based on format\n",
    "    if file_format == 'geojson':\n",
    "        full_path = f\"{output_path}.geojson\"\n",
    "        driver = 'GeoJSON'\n",
    "        gdf.to_file(full_path, driver=driver)\n",
    "\n",
    "    elif file_format == 'shp':\n",
    "        full_path = f\"{output_path}.shp\"\n",
    "        driver = 'ESRI Shapefile'\n",
    "        gdf.to_file(full_path, driver=driver)\n",
    "\n",
    "    elif file_format == 'gpkg':\n",
    "        full_path = f\"{output_path}.gpkg\"\n",
    "        driver = 'GPKG'\n",
    "        gdf.to_file(full_path, driver=driver)\n",
    "\n",
    "    elif file_format == 'parquet':\n",
    "        full_path = f\"{output_path}.parquet\"\n",
    "        gdf.to_parquet(full_path)\n",
    "    \n",
    "    elif file_format=='csv':\n",
    "        full_path=f'{output_path}.csv'\n",
    "        gdf.to_csv(full_path)\n",
    "\n",
    "    print(f\"File successfully written to {full_path}\\n{'-' * 50}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "export_format = 'csv'  #'geojson', 'shp', 'parquet', 'gpkg','csv'\n",
    "stat_operator=['mean','max','min','std', 'median']\n",
    "\n",
    "for stat in stat_operator:\n",
    "\n",
    "    for network in ismn_data.networks:\n",
    "        print(f'Processing network: {network}')\n",
    "\n",
    "        try:\n",
    "\n",
    "            sm = ismn_data[network].to_xarray(variable='soil_moisture')\n",
    "            \n",
    "            if sm is None or len(sm.sensor)==0:\n",
    "                print(f\"No soil moisture data available for network: {network}. Skipping...\\n{'-'*50}\")\n",
    "                continue\n",
    "\n",
    "            # Extract static parameters\n",
    "            static_df = get_static(sm)\n",
    "\n",
    "            # Extract time series soil moisture\n",
    "            ts_df=get_sm_time_series(sm)\n",
    "            ts_df=get_sm_time_series(sm, statistic=stat)\n",
    "\n",
    "            # Merge \n",
    "            merged_df=pd.concat([static_df, ts_df], axis=1)\n",
    "            print('Dimention of static dataframe: ', static_df.shape)\n",
    "            print('Dimention of time series soil moisture dataframe: ',ts_df.shape)\n",
    "            print('Dimention of merged dataframe: ', merged_df.shape)\n",
    "\n",
    "            geometry = [Point(xy) for xy in zip(merged_df['longitude'], merged_df['latitude'])]\n",
    "            gdf = gpd.GeoDataFrame(merged_df, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "            # Build output path without extension\n",
    "            output_path = os.path.join(os.path.split(path)[0], 'extracted_data',stat, f'{network}')\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "            export_gdf(gdf, output_path, file_format=export_format)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing network {network}:{e}\\n{'-'*50}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3da0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
